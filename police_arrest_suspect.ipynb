{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makrai/.local/lib/python3.6/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#from gensim.models import KeyedVectors, TranslationMatrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sktensor\n",
    "import sparse\n",
    "import tensorly as tl\n",
    "\n",
    "from eval_tensor import VerbTensorEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(msecs)d %(levelname)-8s [%(lineno)d] %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()                                            \n",
    "config.read('config.ini')                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor = VerbTensorEvaluator(non_negative=True, weight='npmi', include_empty=False, cutoff=1000000, rank=64)\n",
    "evalor.load_embeddings()\n",
    "tensor = evalor.decomped_tns\n",
    "core = tensor.core\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 8\n",
    "#pylab.rcParams['figure.figsize'] = (2*height, height)\n",
    "\n",
    "plt.matshow(tensor.factors[1][:40])\n",
    "plt.colorbar()\n",
    "#plt.savefig('/home/makrai/repo/paper/Coling2020/verbtensor/img/nonneg-mx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0215cbd438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(np.sort(tensor.factors[1].reshape(-1))[:-10], log=True, bins=100)\n",
    "#plt.savefig('/home/makrai/repo/paper/MSZNY22/verbtensor/img/nonneg-histg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape by cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cufott_and_shape():\n",
    "    for filen in glob.glob('/mnt/permanent/home/makrai/project/verb-tensor/nonempty/tensor/sparstensr_*'):\n",
    "        non_empty = 'non-empty' in filen\n",
    "        cutoff = os.path.splitext(os.path.basename(filen))[0].split('_')[-1]\n",
    "        tensor, _ =  pickle.load(open(filen, mode='rb'))\n",
    "        yield non_empty, cutoff, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(get_cufott_and_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['non_empty', 'cutoff', 'shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cutoff = df.cutoff.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(list(df.columns)).drop_duplicates().set_index('cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.non_empty==True].join(df[df.non_empty==False], lsuffix=' without emtpy', rsuffix=' with emtpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &         shape with emtpy &      shape without emtpy \\\\\n",
      "cutoff   &                          &                          \\\\\n",
      "\\midrule\n",
      "1        &  (324196, 90606, 287967) &  (206488, 41075, 188619) \\\\\n",
      "10       &  (160629, 37427, 129694) &   (109432, 19824, 92635) \\\\\n",
      "100      &    (92999, 20937, 69536) &    (71768, 13907, 57420) \\\\\n",
      "1000     &    (44168, 10444, 32359) &     (40309, 8838, 30280) \\\\\n",
      "10000    &     (13765, 5070, 12313) &     (13610, 4895, 12115) \\\\\n",
      "30000    &       (7395, 3568, 7524) &       (7349, 3526, 7460) \\\\\n",
      "50000    &       (5438, 2994, 5881) &       (5411, 2976, 5843) \\\\\n",
      "100000   &       (3474, 2313, 4120) &       (3463, 2308, 4108) \\\\\n",
      "300000   &       (1515, 1438, 2200) &       (1512, 1438, 2197) \\\\\n",
      "1000000  &          (546, 814, 981) &          (545, 813, 980) \\\\\n",
      "3000000  &          (168, 461, 399) &          (167, 461, 398) \\\\\n",
      "10000000 &            (36, 194, 87) &            (35, 194, 86) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df.isna().sum(axis=1)==0,['shape with emtpy', 'shape without emtpy']].to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_names = ['nsubj', 'ROOT', 'dobj']\n",
    "\n",
    "def show_latent(evalor, latent_i, mode_i):\n",
    "    surf_indices = evalor.decomped_tns.factors[mode_i][:,latent_i]\n",
    "    if isinstance(surf_indices, sparse.COO):\n",
    "        surf_indices = surf_indices.todense()\n",
    "    surf_indices = np.argsort(-surf_indices)\n",
    "    return latent_i, ', '.join([evalor.index[mode_names[mode_i]].inv[surf_i] for surf_i in surf_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum_latent(non_negative=True, decomp_algo='parafac', k_to_show=4):\n",
    "    records = []\n",
    "    if decomp_algo == 'parafac':\n",
    "        if non_negative:\n",
    "            evalor = VerbTensorEvaluator(non_negative=non_negative)\n",
    "        else:\n",
    "            evalor = VerbTensorEvaluator(non_negative=non_negative, decomp_algo=decomp_algo, \n",
    "                                         weight='npmi', include_empty=False, cutoff=300000, rank=256)\n",
    "        evalor.load_embeddings()\n",
    "        indices = [(i,i,i) for i in  range(k_to_show)]\n",
    "    else:\n",
    "        if non_negative:\n",
    "            evalor = VerbTensorEvaluator(non_negative=non_negative, decomp_algo=decomp_algo,\n",
    "                                         weight='npmi', include_empty=False, cutoff=1000000, rank=64)\n",
    "        else:\n",
    "            evalor = VerbTensorEvaluator(non_negative=non_negative, decomp_algo=decomp_algo,\n",
    "                                         weight='npmi', include_empty=True, cutoff=100000, rank=64)            \n",
    "        evalor.load_embeddings()\n",
    "        core = evalor.decomped_tns.core\n",
    "        indices = zip(*np.unravel_index(np.argsort(-core.reshape(-1))[:k_to_show], core.shape))\n",
    "    for i, j, k in indices:\n",
    "        records.append(show_latent(evalor, i, 0))\n",
    "        records.append(show_latent(evalor, j, 1))\n",
    "        records.append(show_latent(evalor, k, 2))\n",
    "    print(pd.DataFrame(records, columns=['dim', 'words']).set_index('dim').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('lw', 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                                                                      words \\\\\n",
      "dim &                                                                                            \\\\\n",
      "\\midrule\n",
      "0   &  , that, which, it, story, he, they, who, what, one, she, work, event, -rrb-, this, you... \\\\\n",
      "0   &  catch, attract, draw, pay, deserve, capture, gain, grab, get, receive, focus, require,... \\\\\n",
      "0   &  attention, eye, crowd, interest, fire, visitor, audience, conclusion, breath, people, ... \\\\\n",
      "1   &  , who, we, he, I, you, she, they, -rrb-, student, member, people, group, Center, parti... \\\\\n",
      "1   &  attend, host, hold, organize, schedule, enjoy, join, arrange, cancel, miss, watch, pla... \\\\\n",
      "1   &  meeting, event, conference, session, party, show, school, class, dinner, church, tour,... \\\\\n",
      "2   &  that, which, it, this, , change, factor, they, choice, condition, decision, issue, -rr... \\\\\n",
      "2   &  affect, impact, influence, improve, hurt, reflect, benefit, change, damage, enhance, a... \\\\\n",
      "2   &  ability, performance, health, outcome, life, quality, result, business, development, e... \\\\\n",
      "3   &  file, which, page, site, that, it, book, report, section, document, collection, websit... \\\\\n",
      "3   &  contain, include, provide, have, list, feature, display, show, comprise, present, give... \\\\\n",
      "3   &  information, link, material, number, list, datum, name, content, statement, reference,... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enum_latent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                                                                      words \\\\\n",
      "dim &                                                                                            \\\\\n",
      "\\midrule\n",
      "5   &  court, Court, judge, panel, official, we, he, it, authority, government, -rrb-, Board,... \\\\\n",
      "10  &  reject, dismiss, deny, grant, hear, consider, decide, accept, throw, resolve, sustain,... \\\\\n",
      "7   &  motion, appeal, claim, request, argument, case, challenge, application, complaint, att... \\\\\n",
      "4   &  revenue, sale, share, price, stock, production, cost, rate, order, volume, number, fut... \\\\\n",
      "3   &  rise, fall, increase, jump, drop, decline, climb, decrease, grow, gain, slip, represen... \\\\\n",
      "1   &  percent, \\%, \\$, increase, point, most, rate, level, average, less, matter, value, cost,... \\\\\n",
      "11  &  hotel, property, room, restaurant, home, Center, house, location, facility, House, are... \\\\\n",
      "8   &  offer, boast, feature, have, provide, include, enjoy, serve, accommodate, occupy, prep... \\\\\n",
      "9   &  room, pool, accommodation, access, facility, restaurant, variety, service, view, range... \\\\\n",
      "6   &  board, Council, Board, Commission, Committee, member, committee, Congress, Court, cour... \\\\\n",
      "2   &  approve, adopt, reject, pass, consider, review, endorse, propose, award, recommend, ac... \\\\\n",
      "2   &  resolution, request, budget, plan, proposal, contract, change, application, project, i... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enum_latent(decomp_algo='tucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                                                                      words \\\\\n",
      "dim &                                                                                            \\\\\n",
      "\\midrule\n",
      "0   &  Israel, group, government, Foundation, Association, company, -rrb-, military, army, Cl... \\\\\n",
      "0   &  launch, wage, suspend, mount, begin, run, fund, organize, sponsor, administer, carry, ... \\\\\n",
      "0   &  campaign, attack, program, initiative, operation, strike, programme, website, effort, ... \\\\\n",
      "1   &  user, you, application, customer, developer, visitor, client, processor, device, User,... \\\\\n",
      "1   &  access, select, specify, upload, view, enter, edit, browse, click, create, retrieve, m... \\\\\n",
      "1   &  file, datum, content, document, page, parameter, site, folder, node, Internet, informa... \\\\\n",
      "2   &  device, assembly, means, structure, system, element, plate, section, interface, unit, ... \\\\\n",
      "2   &  comprise, include, contain, have, utilize, employ, represent, say, mean, control, enab... \\\\\n",
      "2   &  layer, element, device, tube, housing, spring, electrode, pump, plate, container, memb... \\\\\n",
      "3   &  attorney, plaintiff, defendant, party, respondent, prosecutor, State, lawyer, governme... \\\\\n",
      "3   &  file, receive, oppose, make, give, present, withdraw, handle, publish, drop, provide, ... \\\\\n",
      "3   &  motion, notice, petition, appeal, response, answer, objection, charge, request, submis... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enum_latent(decomp_algo='parafac', non_negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                                                                      words \\\\\n",
      "dim &                                                                                            \\\\\n",
      "\\midrule\n",
      "0   &  , that, we, you, they, he, I, who, which, it, she, -rrb-, this, company, people, stude... \\\\\n",
      "0   &  have, include, provide, use, create, bring, give, support, produce, regard, put, offer... \\\\\n",
      "0   &  , they, system, it, number, the, program, area, he, information, datum, value, process... \\\\\n",
      "1   &  , Benefiting, MagicSearch, incase, LOOMIS, Knetbooks, ATOL, Woot, para, BabyCenter, Li... \\\\\n",
      "1   &  have, provide, offer, create, use, include, give, contain, regard, enhance, maintain, ... \\\\\n",
      "1   &  , what, percent, \\%, that, \\$, point, which, I, way, game, -rsb-, who, increase, more, c... \\\\\n",
      "0   &  , that, we, you, they, he, I, who, which, it, she, -rrb-, this, company, people, stude... \\\\\n",
      "4   &  have, tell, ask, kill, inform, meet, convince, assist, remind, teach, invite, support,... \\\\\n",
      "3   &  I, he, we, she, you, people, other, woman, man, they, anyone, child, student, person, ... \\\\\n",
      "1   &  , Benefiting, MagicSearch, incase, LOOMIS, Knetbooks, ATOL, Woot, para, BabyCenter, Li... \\\\\n",
      "2   &  regard, concern, protect, prevent, surround, attack, promote, destroy, defend, monitor... \\\\\n",
      "0   &  , they, system, it, number, the, program, area, he, information, datum, value, process... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enum_latent(decomp_algo='tucker', non_negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                           subjects \\\\\n",
      "dim &                                                    \\\\\n",
      "\\midrule\n",
      "6   &  board, Council, Board, Commission, Committee, ... \\\\\n",
      "7   &  study, result, analysis, finding, datum, resea... \\\\\n",
      "8   &  -rsb-, -lsb-, reference, effect, role, cell, e... \\\\\n",
      "9   &  Department, police, Center, official, -rrb-, d... \\\\\n",
      "10  &  article, paper, report, section, study, course... \\\\\n",
      "11  &  hotel, property, room, restaurant, home, Cente... \\\\\n",
      "12  &  factor, condition, comment, activity, choice, ... \\\\\n",
      "13  &  paper, author, course, company, scientist, res... \\\\\n",
      "14  &  course, program, plan, applicant, student, sol... \\\\\n",
      "15  &  event, year, band, show, couple, Inc., Center,... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for i in range(6,16):\n",
    "    records.append(show_latent(i, 0))\n",
    "print(pd.DataFrame(records, columns=['dim', 'subjects']).set_index('dim').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                              verbs \\\\\n",
      "dim &                                                    \\\\\n",
      "\\midrule\n",
      "0   &  include, provide, illustrate, show, feature, c... \\\\\n",
      "1   &  illustrate, show, depict, represent, comprise,... \\\\\n",
      "2   &  approve, adopt, reject, pass, consider, review... \\\\\n",
      "3   &  rise, fall, increase, jump, drop, decline, cli... \\\\\n",
      "4   &  provide, present, give, include, describe, rev... \\\\\n",
      "5   &  -lsb-\\_VBD, -lsb-\\_VBP, quote, -lsb-\\_VB, /, rese... \\\\\n",
      "6   &  issue, release, publish, receive, prepare, sub... \\\\\n",
      "7   &  exceed, represent, reflect, match, reach, aver... \\\\\n",
      "8   &  offer, boast, feature, have, provide, include,... \\\\\n",
      "9   &  present, describe, examine, propose, explore, ... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for i in range(10):\n",
    "    records.append(show_latent(i, 1))\n",
    "print(pd.DataFrame(records, columns=['dim', 'verbs']).set_index('dim').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                            objects \\\\\n",
      "dim &                                                    \\\\\n",
      "\\midrule\n",
      "0   &  example, view, structure, configuration, chart... \\\\\n",
      "1   &  percent, \\%, \\$, increase, point, most, rate, le... \\\\\n",
      "2   &  resolution, request, budget, plan, proposal, c... \\\\\n",
      "3   &  -rsb-, column, 1, 4, 5, 3, debut, 2, detail, r... \\\\\n",
      "4   &  -rsb-, device, module, unit, portion, pluralit... \\\\\n",
      "5   &  suit, complaint, motion, appeal, report, notic... \\\\\n",
      "6   &  \\$, dollar, more, million, less, increase, hund... \\\\\n",
      "7   &  motion, appeal, claim, request, argument, case... \\\\\n",
      "8   &  overview, approach, analysis, method, finding,... \\\\\n",
      "9   &  room, pool, accommodation, access, facility, r... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for i in range(10):\n",
    "    records.append(show_latent(i, 2))\n",
    "print(pd.DataFrame(records, columns=['dim', 'objects']).set_index('dim').to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete ... race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = KeyedVectors(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.add_vectors(list(evalor.index['ROOT'].inv.values()), tensor.factors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_verb(subj='athlete', obj='race'):\n",
    "    tensor1 = tensor.core\n",
    "    tensor1 = tl.tenalg.mode_dot(tensor1, evalor.lookup(subj, 0), 0)\n",
    "    tensor1 = tl.tenalg.mode_dot(tensor1, evalor.lookup(obj, 2), 1)\n",
    "    return embed.most_similar([tensor1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_verb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_verb(subj='user', obj='command')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.factors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dir = config['DEFAULT']['ProjectDirectory']+'tensor/'\n",
    "evalor = VerbTensorEvaluator(cutoff=50000, rank=256, weight='npmi', decomp_algo='parafac')\n",
    "modes = ['nsubj', 'ROOT', 'dobj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.sort(evalor.decomped_tns.factors[1].reshape(-1).todense())[:-10], log=True, bins=100)\n",
    "plt.savefig('/home/makrai/repo/paper/CONLL21//verbtensor/img/posibneg-histg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor.decomped_tns.weights.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_word = [{i: w for w, i in evalor.index[j].items()} for j in modes]\n",
    "vocab = [np.array([i_word[j][i] for i in range(len(i_word[j]))]) for j in range(len(i_word))]\n",
    "for k, j in enumerate(\n",
    "        #np.argsort(-ktensor.lmbda)[:4]):#\n",
    "        range(evalor.decomped_tns.rank)):\n",
    "    print(f'\\n{k}')# {j}')\n",
    "    for i, factor in enumerate(evalor.decomped_tns.factors):\n",
    "        ids = np.argsort(factor[:,j].todense())[:7]\n",
    "        print(vocab[i][ids])\n",
    "        #print(['{:.1g}'.format(coord) for coord in ktensor.U[i][ids,j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|rank|$\\lambda$|e.g.|\n",
    "|----|---------|----|\n",
    "|16|1|topic/example (2) provide/offer (2) assistance/guidance|\n",
    "|32|1|Android (3)  win degree (1)|\n",
    "|64|1|I describe (1) game/story (2)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

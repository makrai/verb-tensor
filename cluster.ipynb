{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "import nltk\n",
    "from nltk.corpus import verbnet as vn\n",
    "import pandas as pd\n",
    "from sklearn.cluster import SpectralClustering, MeanShift\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score, adjusted_rand_score, adjusted_mutual_info_score, v_measure_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "from cluster import ClusterVerbs\n",
    "from eval_tensor import VerbTensorEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compared otVerbNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_verbnet(non_negative=False, decomp_algo='tucker', rank=64, cutoff=100000, weight='npmi',\n",
    "                       min_cluster_size=50, min_samples=5):\n",
    "    evalor = VerbTensorEvaluator(non_negative=non_negative, decomp_algo=decomp_algo, \n",
    "                                 rank=rank, cutoff=cutoff, weight=weight)\n",
    "    evalor.load_embeddings()\n",
    "    df = pd.DataFrame(evalor.index['ROOT'], columns=['verb'])\n",
    "    df['vnet'] = df.verb.apply(lambda verb: vn.classids(lemma=verb))\n",
    "    mapper = UMAP(n_neighbors=30, min_dist=0.0, n_components=10, metric='cosine')\n",
    "    lowdim_vecs = mapper.fit_transform(evalor.decomped_tns.factors[1])\n",
    "    clusser = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "    df['cluster'] = clusser.fit_predict(lowdim_vecs)\n",
    "    return df, adjusted_rand_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clusters(df):\n",
    "    return pd.DataFrame(\n",
    "        [(i, size, ', '.join(df[df.cluster==i].verb.values))\n",
    "         for i, size in df.groupby('cluster').size().sort_values(ascending=False).head(20).to_dict().items()],\n",
    "        columns=['index', 'n_verbs', 'verbs']).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posibneg, score = compare_to_verbnet(min_cluster_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_verbs</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>514</td>\n",
       "      <td>be, take, provide, include, mean, keep, put, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114</td>\n",
       "      <td>kill, catch, shoot, treat, trust, bear, feed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97</td>\n",
       "      <td>wish, wonder, care, listen, gon, gather, pray,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80</td>\n",
       "      <td>break, pull, push, lay, stick, roll, touch, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>commit, repeat, expose, separate, heal, distin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>tell, ask, call, thank, please, join, contact,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>69</td>\n",
       "      <td>check, view, click, display, generate, update,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>67</td>\n",
       "      <td>leave, enter, visit, fill, reserve, clean, cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "      <td>live, wait, sleep, laugh, sing, cry, smile, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61</td>\n",
       "      <td>remind, strike, worry, blow, inspire, bother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>do, make, think, know, see, want, find, need, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>51</td>\n",
       "      <td>have, get, give, receive, win, lose, seek, ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>47</td>\n",
       "      <td>use, replace, install, connect, test, switch, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>47</td>\n",
       "      <td>improve, protect, maintain, achieve, ensure, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46</td>\n",
       "      <td>fail, focus, vote, act, deal, attempt, rely, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>rate, /, -lsb-_VBD, rank, -lsb-_VB, \\, -lsb-_V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>33</td>\n",
       "      <td>wear, paint, tear, rip, rock, sew, fold, don, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>try, believe, agree, decide, claim, argue, ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>grow, fall, drop, rise, jump, decline, trade, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>28</td>\n",
       "      <td>cause, answer, address, fix, handle, solve, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_verbs                                              verbs\n",
       "index                                                            \n",
       "-1         514  be, take, provide, include, mean, keep, put, p...\n",
       " 9         114  kill, catch, shoot, treat, trust, bear, feed, ...\n",
       " 18         97  wish, wonder, care, listen, gon, gather, pray,...\n",
       " 34         80  break, pull, push, lay, stick, roll, touch, pr...\n",
       " 3          78  commit, repeat, expose, separate, heal, distin...\n",
       " 11         76  tell, ask, call, thank, please, join, contact,...\n",
       " 57         69  check, view, click, display, generate, update,...\n",
       " 26         67  leave, enter, visit, fill, reserve, clean, cro...\n",
       " 19         62  live, wait, sleep, laugh, sing, cry, smile, re...\n",
       " 10         61  remind, strike, worry, blow, inspire, bother, ...\n",
       " 7          60  do, make, think, know, see, want, find, need, ...\n",
       " 32         51  have, get, give, receive, win, lose, seek, ass...\n",
       " 59         47  use, replace, install, connect, test, switch, ...\n",
       " 50         47  improve, protect, maintain, achieve, ensure, a...\n",
       " 27         46  fail, focus, vote, act, deal, attempt, rely, s...\n",
       " 1          33  rate, /, -lsb-_VBD, rank, -lsb-_VB, \\, -lsb-_V...\n",
       " 38         33  wear, paint, tear, rip, rock, sew, fold, don, ...\n",
       " 31         32  try, believe, agree, decide, claim, argue, ref...\n",
       " 2          30  grow, fall, drop, rise, jump, decline, trade, ...\n",
       " 41         28  cause, answer, address, fix, handle, solve, re..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_clusters(df_posibneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\"iact\" ,\"iact_sali\" ,\"ldice\" ,\"ldice_sali\" ,\"log_freq\" ,\"niact\" ,\"npmi\" ,\"pmi\" ,\"pmi_sali\"]\n",
    "\n",
    "cutoffs = []\n",
    "for i in [1, 2, 3, 5]:\n",
    "    cutoffs += list(i*10**np.arange(2, 9))\n",
    "\n",
    "def eval_agains_verbnet_for(algo='tucker'):    \n",
    "    data = []\n",
    "    for non_negative in range(2):\n",
    "        for cutoff in cutoffs:\n",
    "            for exp in range(10):\n",
    "                rank = 2**exp\n",
    "                for weight in weights:\n",
    "                    try:\n",
    "                        _, score = compare_to_verbnet(non_negative=non_negative, decomp_algo=algo,\n",
    "                                                   rank=rank, cutoff=cutoff, weight=weight)\n",
    "                        record = (cutoff, rank, weight, non_negative, algo, score)\n",
    "                        logging.info((record))\n",
    "                        data.append(record)\n",
    "                    except FileNotFoundError:\n",
    "                        pass\n",
    "                    except AttributeError as e:\n",
    "                        logging.warning((record, e))\n",
    "                    except ValueError:\n",
    "                        logging.warning(record)\n",
    "    df = pd.DataFrame(data, columns=['cutoff', 'rank', 'weight', 'non_negative', 'algo', 'corr'])\n",
    "    return df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makrai/tool/python/vtensor/lib/python3.7/site-packages/umap/umap_.py:126: UserWarning: A few of your vertices were disconnected from the manifold.  This shouldn't cause problems.\n",
      "Disconnection_distance = 1 has removed 340 edges.\n",
      "It has only fully disconnected 4 vertices.\n",
      "Use umap.utils.disconnected_vertices() to identify them.\n",
      "  f\"A few of your vertices were disconnected from the manifold.  This shouldn't cause problems.\\n\"\n",
      "WARNING:root:(10000, 2, 'log_freq', 0, 'tucker')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 53s, sys: 24.6 s, total: 55min 17s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%time score_df = eval_agains_verbnet_for()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>non_negative</th>\n",
       "      <th>algo</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50000</td>\n",
       "      <td>32</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>iact</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.021839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50000</td>\n",
       "      <td>64</td>\n",
       "      <td>pmi_sali</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.020478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>npmi</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.018066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.015387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>300000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.012484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>500000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.015166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>500000</td>\n",
       "      <td>64</td>\n",
       "      <td>npmi</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.018261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50000</td>\n",
       "      <td>4</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.018422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cutoff  rank    weight  non_negative    algo      corr\n",
       "31   50000    32  log_freq             0  tucker  0.022485\n",
       "3   100000    64      iact             0  tucker  0.021839\n",
       "40   50000    64  pmi_sali             0  tucker  0.020478\n",
       "9   100000    64      npmi             0  tucker  0.018066\n",
       "1     1000     4  log_freq             0  tucker  0.015387\n",
       "..     ...   ...       ...           ...     ...       ...\n",
       "53  300000    64  log_freq             1  tucker -0.012484\n",
       "59  500000    64  log_freq             1  tucker -0.015166\n",
       "60  500000    64      npmi             1  tucker -0.017200\n",
       "26  300000    64  log_freq             0  tucker -0.018261\n",
       "28   50000     4  log_freq             0  tucker -0.018422\n",
       "\n",
       "[61 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "-1     547\n",
       " 29    100\n",
       " 21     98\n",
       " 30     94\n",
       " 45     88\n",
       " 25     81\n",
       " 16     77\n",
       " 5      71\n",
       " 19     70\n",
       " 4      69\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('cluster').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(df.vnet.astype(str)).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_clust = df.groupby(df.cluster).size().sort_values(ascending=False).values\n",
    "plt.plot(ser_clust + 1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_class = df.groupby(df.vnet.astype(str)).size().sort_values(ascending=False)\n",
    "plt.plot(ser_class+1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.vnet.str.len()!=0)&(df.cluster!=-1)]\n",
    "df1.groupby(['cluster', df1.vnet.astype(str)]).size().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_mutual_info_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fowlkes_mallows_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(df.vnet.apply(lambda l: 'amuse-31.1' in l), df.cluster==14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*verb_mx.T[0:], s=3, c=df.index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist2d(df.index, df.vnet.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_class(classes):\n",
    "    if classes:\n",
    "        return min([int(class_.split('-')[1].split('.')[0]) for class_ in classes])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['least_class'] = df.vnet.apply(least_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.least_class.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.vnet.str.len()==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = df.groupby('least_class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.name = 'lclass_size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('least_class').join(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.least_class==9].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = (df.lclass_size > 50).values\n",
    "plt.scatter(*verb_mx[part].T, s=5, c=df.least_class[part])#==9)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtens",
   "language": "python",
   "name": "vtens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

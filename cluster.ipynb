{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "import nltk\n",
    "from nltk.corpus import verbnet as vn\n",
    "import pandas as pd\n",
    "from sklearn.cluster import SpectralClustering, MeanShift\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score, adjusted_rand_score, adjusted_mutual_info_score, v_measure_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "from cluster import ClusterVerbs\n",
    "from eval_tensor import VerbTensorEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compared otVerbNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_verbnet(non_negative=False, decomp_algo='tucker', rank=64, cutoff=100000, weight='npmi',\n",
    "                       min_cluster_size=50, min_samples=5):\n",
    "    evalor = VerbTensorEvaluator(non_negative=non_negative, decomp_algo=decomp_algo, \n",
    "                                 rank=rank, cutoff=cutoff, weight=weight)\n",
    "    evalor.load_embeddings()\n",
    "    df = pd.DataFrame(evalor.index['ROOT'], columns=['verb'])\n",
    "    df['vnet'] = df.verb.apply(lambda verb: vn.classids(lemma=verb))\n",
    "    mapper = UMAP(n_neighbors=30, min_dist=0.0, n_components=10, metric='cosine')\n",
    "    lowdim_vecs = mapper.fit_transform(evalor.decomped_tns.factors[1])\n",
    "    clusser = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "    df['cluster'] = clusser.fit_predict(lowdim_vecs)\n",
    "    return df, adjusted_rand_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &                                              verbs \\\\\n",
      "n\\_verbs &                                                    \\\\\n",
      "\\midrule\n",
      "1132    &  have, take, give, show, read, include, keep, p... \\\\\n",
      "315     &  hurt, wake, inspire, bother, surprise, satisfy... \\\\\n",
      "246     &  gon, wan, subscribe, reside, stumble, behave, ... \\\\\n",
      "114     &  eat, drink, cook, burn, taste, wash, pour, pac... \\\\\n",
      "103     &  break, fit, draw, catch, shoot, extend, beat, ... \\\\\n",
      "92      &  provide, create, offer, pay, spend, build, con... \\\\\n",
      "92      &  receive, support, seek, accept, sign, obtain, ... \\\\\n",
      "80      &  believe, hope, agree, decide, report, plan, ex... \\\\\n",
      "72      &  happen, lead, apply, occur, exist, tend, resul... \\\\\n",
      "68      &  stop, cause, cover, manage, face, prevent, avo... \\\\\n",
      "64      &  live, talk, stand, die, return, pass, walk, si... \\\\\n",
      "62      &  leave, open, enter, visit, close, fill, fix, r... \\\\\n",
      "58      &  be, get, say, make, go, use, think, know, see,... \\\\\n",
      "54      &  regret, spell, board, voice, crave, misspell, ... \\\\\n",
      "53      &  display, generate, collect, release, store, ga... \\\\\n",
      "53      &  combine, capture, integrate, incorporate, adap... \\\\\n",
      "52      &  part, moderate, flag, chart, chill, quilt, spl... \\\\\n",
      "50      &  lose, maintain, gain, establish, expand, expre... \\\\\n",
      "45      &  install, connect, test, switch, design, modify... \\\\\n",
      "33      &  do, start, begin, continue, follow, end, perfo... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(\n",
    "    [(size, ', '.join(df[df.cluster==i].verb.values))\n",
    "     for i, size in df.groupby('cluster').size().sort_values(ascending=False).head(20).to_dict().items()],\n",
    "    columns=['n_verbs', 'verbs']).set_index('n_verbs').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\"iact\" ,\"iact_sali\" ,\"ldice\" ,\"ldice_sali\" ,\"log_freq\" ,\"niact\" ,\"npmi\" ,\"pmi\" ,\"pmi_sali\"]\n",
    "\n",
    "cutoffs = []\n",
    "for i in [1, 2, 3, 5]:\n",
    "    cutoffs += list(i*10**np.arange(2, 9))\n",
    "\n",
    "def eval_agains_verbnet_for(algo='tucker'):    \n",
    "    data = []\n",
    "    for non_negative in range(2):\n",
    "        for cutoff in cutoffs:\n",
    "            for exp in range(10):\n",
    "                rank = 2**exp\n",
    "                for weight in weights:\n",
    "                    try:\n",
    "                        _, score = compare_to_verbnet(non_negative=non_negative, decomp_algo=algo,\n",
    "                                                   rank=rank, cutoff=cutoff, weight=weight)\n",
    "                        record = (cutoff, rank, weight, non_negative, algo, score)\n",
    "                        logging.info((record))\n",
    "                        data.append(record)\n",
    "                    except FileNotFoundError:\n",
    "                        pass\n",
    "                    except AttributeError as e:\n",
    "                        logging.warning((record, e))\n",
    "                    except ValueError:\n",
    "                        logging.warning(record)\n",
    "    df = pd.DataFrame(data, columns=['cutoff', 'rank', 'weight', 'non_negative', 'algo', 'corr'])\n",
    "    return df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makrai/tool/python/vtensor/lib/python3.7/site-packages/umap/umap_.py:126: UserWarning: A few of your vertices were disconnected from the manifold.  This shouldn't cause problems.\n",
      "Disconnection_distance = 1 has removed 340 edges.\n",
      "It has only fully disconnected 4 vertices.\n",
      "Use umap.utils.disconnected_vertices() to identify them.\n",
      "  f\"A few of your vertices were disconnected from the manifold.  This shouldn't cause problems.\\n\"\n",
      "WARNING:root:(10000, 2, 'log_freq', 0, 'tucker')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 53s, sys: 24.6 s, total: 55min 17s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%time score_df = eval_agains_verbnet_for()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>non_negative</th>\n",
       "      <th>algo</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50000</td>\n",
       "      <td>32</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>iact</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.021839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50000</td>\n",
       "      <td>64</td>\n",
       "      <td>pmi_sali</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.020478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>npmi</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.018066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>0.015387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>300000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.012484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>500000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.015166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>500000</td>\n",
       "      <td>64</td>\n",
       "      <td>npmi</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300000</td>\n",
       "      <td>64</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.018261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50000</td>\n",
       "      <td>4</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>tucker</td>\n",
       "      <td>-0.018422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cutoff  rank    weight  non_negative    algo      corr\n",
       "31   50000    32  log_freq             0  tucker  0.022485\n",
       "3   100000    64      iact             0  tucker  0.021839\n",
       "40   50000    64  pmi_sali             0  tucker  0.020478\n",
       "9   100000    64      npmi             0  tucker  0.018066\n",
       "1     1000     4  log_freq             0  tucker  0.015387\n",
       "..     ...   ...       ...           ...     ...       ...\n",
       "53  300000    64  log_freq             1  tucker -0.012484\n",
       "59  500000    64  log_freq             1  tucker -0.015166\n",
       "60  500000    64      npmi             1  tucker -0.017200\n",
       "26  300000    64  log_freq             0  tucker -0.018261\n",
       "28   50000     4  log_freq             0  tucker -0.018422\n",
       "\n",
       "[61 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "-1     547\n",
       " 29    100\n",
       " 21     98\n",
       " 30     94\n",
       " 45     88\n",
       " 25     81\n",
       " 16     77\n",
       " 5      71\n",
       " 19     70\n",
       " 4      69\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('cluster').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(df.vnet.astype(str)).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_clust = df.groupby(df.cluster).size().sort_values(ascending=False).values\n",
    "plt.plot(ser_clust + 1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_class = df.groupby(df.vnet.astype(str)).size().sort_values(ascending=False)\n",
    "plt.plot(ser_class+1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.vnet.str.len()!=0)&(df.cluster!=-1)]\n",
    "df1.groupby(['cluster', df1.vnet.astype(str)]).size().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_mutual_info_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fowlkes_mallows_score(df.vnet.astype(str), df.cluster.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(df.vnet.apply(lambda l: 'amuse-31.1' in l), df.cluster==14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*verb_mx.T[0:], s=3, c=df.index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist2d(df.index, df.vnet.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_class(classes):\n",
    "    if classes:\n",
    "        return min([int(class_.split('-')[1].split('.')[0]) for class_ in classes])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['least_class'] = df.vnet.apply(least_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.least_class.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.vnet.str.len()==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = df.groupby('least_class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.name = 'lclass_size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('least_class').join(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.least_class==9].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = (df.lclass_size > 50).values\n",
    "plt.scatter(*verb_mx[part].T, s=5, c=df.least_class[part])#==9)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtens",
   "language": "python",
   "name": "vtens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

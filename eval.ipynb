{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makrai/tool/python/vtensor/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from copy import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import tensorly as tl\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "from eval_tensor import VerbTensorEvaluator\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "        format='%(levelname)-8s [%(lineno)d] %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 One-mode similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data\n",
    "\n",
    "### 1.1.1 [SimVerb](http://people.ds.cam.ac.uk/dsg40/simverb.html) (Gerz+ EMNLP 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb = pd.read_csv('/mnt/permanent/Language/English/Data/verb-similarity/simverb-3500/SimVerb-3500.txt', \n",
    "                      sep='\\t', header=None, names=['verb1', 'verb2', 'pos', 'sim', 'rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb1</th>\n",
       "      <th>verb2</th>\n",
       "      <th>pos</th>\n",
       "      <th>sim</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take</td>\n",
       "      <td>remove</td>\n",
       "      <td>V</td>\n",
       "      <td>6.81</td>\n",
       "      <td>SYNONYMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walk</td>\n",
       "      <td>trail</td>\n",
       "      <td>V</td>\n",
       "      <td>4.81</td>\n",
       "      <td>COHYPONYMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feed</td>\n",
       "      <td>starve</td>\n",
       "      <td>V</td>\n",
       "      <td>1.49</td>\n",
       "      <td>ANTONYMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shine</td>\n",
       "      <td>polish</td>\n",
       "      <td>V</td>\n",
       "      <td>7.80</td>\n",
       "      <td>SYNONYMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate</td>\n",
       "      <td>add</td>\n",
       "      <td>V</td>\n",
       "      <td>5.98</td>\n",
       "      <td>HYPER/HYPONYMS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb1   verb2 pos   sim             rel\n",
       "0       take  remove   V  6.81        SYNONYMS\n",
       "1       walk   trail   V  4.81      COHYPONYMS\n",
       "2       feed  starve   V  1.49        ANTONYMS\n",
       "3      shine  polish   V  7.80        SYNONYMS\n",
       "4  calculate     add   V  5.98  HYPER/HYPONYMS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simverb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.291554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.652621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sim\n",
       "count  3500.000000\n",
       "mean      4.291554\n",
       "std       2.652621\n",
       "min       0.000000\n",
       "50%       4.320000\n",
       "max       9.960000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simverb.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NONE</th>\n",
       "      <td>2093.0</td>\n",
       "      <td>3.431276</td>\n",
       "      <td>2.342695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.150</td>\n",
       "      <td>9.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYPER/HYPONYMS</th>\n",
       "      <td>800.0</td>\n",
       "      <td>6.012525</td>\n",
       "      <td>2.104537</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.310</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYNONYMS</th>\n",
       "      <td>306.0</td>\n",
       "      <td>6.789150</td>\n",
       "      <td>2.104490</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.140</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COHYPONYMS</th>\n",
       "      <td>190.0</td>\n",
       "      <td>4.435526</td>\n",
       "      <td>2.381992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.665</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANTONYMS</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.977748</td>\n",
       "      <td>1.074232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>6.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean       std  min    50%   max\n",
       "rel                                                         \n",
       "NONE            2093.0  3.431276  2.342695  0.0  3.150  9.79\n",
       "HYPER/HYPONYMS   800.0  6.012525  2.104537  0.5  6.310  9.96\n",
       "SYNONYMS         306.0  6.789150  2.104490  0.5  7.140  9.96\n",
       "COHYPONYMS       190.0  4.435526  2.381992  0.0  4.665  9.30\n",
       "ANTONYMS         111.0  0.977748  1.074232  0.0  0.660  6.04"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simverb.groupby('rel').sim.describe(percentiles=[]).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 SimLex-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex = pd.read_csv('/mnt/permanent/Language/English/Data/SimLex-999/SimLex-999.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* conc(w1): The concreteness rating of word1 on a scale of 1-7. Taken from the University of South Florida Free Association Norms database. \n",
    "\n",
    "* conc(w2): The concreteness rating of word2 on a scale of 1-7. Taken from the University of South Florida Free Association Norms database. \n",
    "\n",
    "* concQ: The quartile the pair occupies based on the two concreteness ratings. Used for some analyses in the above paper. \n",
    "\n",
    "* Assoc(USF): The strength of free association from word1 to word2. Values are taken from the University of South Florida Free Association Dataset. \n",
    "\n",
    "* SimAssoc333: Binary indicator of whether the pair is one of the 333 most associated in the dataset (according to Assoc(USF)). This subset of SimLex999 is often the hardest for computational models to capture because the noise from high association can confound the similarity rating. See the paper for more details. \n",
    "\n",
    "* SD(SimLex): The standard deviation of annotator scores when rating this pair. Low values indicate good agreement between the 15+ annotators on the similarity value SimLex999. Higher scores indicate less certainty. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.561572</td>\n",
       "      <td>3.657087</td>\n",
       "      <td>3.568629</td>\n",
       "      <td>2.501502</td>\n",
       "      <td>0.751512</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.274505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.614663</td>\n",
       "      <td>1.131050</td>\n",
       "      <td>1.159572</td>\n",
       "      <td>1.118145</td>\n",
       "      <td>1.344569</td>\n",
       "      <td>0.471641</td>\n",
       "      <td>0.366278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.670000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimLex999    conc(w1)    conc(w2)       concQ  Assoc(USF)  \\\n",
       "count  999.000000  999.000000  999.000000  999.000000  999.000000   \n",
       "mean     4.561572    3.657087    3.568629    2.501502    0.751512   \n",
       "std      2.614663    1.131050    1.159572    1.118145    1.344569   \n",
       "min      0.230000    1.190000    1.190000    1.000000    0.000000   \n",
       "50%      4.670000    3.830000    3.660000    3.000000    0.250000   \n",
       "max      9.800000    5.000000    5.000000    4.000000    8.850000   \n",
       "\n",
       "       SimAssoc333  SD(SimLex)  \n",
       "count   999.000000  999.000000  \n",
       "mean      0.333333    1.274505  \n",
       "std       0.471641    0.366278  \n",
       "min       0.000000    0.340000  \n",
       "50%       0.000000    1.310000  \n",
       "max       1.000000    2.180000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS\n",
       "A    111\n",
       "N    666\n",
       "V    222\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex.groupby('POS').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Testing the verb tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor = VerbTensorEvaluator(include_empty=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\"iact\" ,\"iact_sali\" ,\"ldice\" ,\"ldice_sali\" ,\"log_freq\" ,\"niact\" ,\"npmi\" ,\"pmi\" ,\"pmi_sali\"]\n",
    "\n",
    "cutoffs = []\n",
    "for i in [1, 2, 3, 5]:\n",
    "    cutoffs += list(i*10**np.arange(2, 9))\n",
    "\n",
    "def eval_for_for(task_df0, mode_to_test, algo='tucker'):\n",
    "    # normlz_vocb=True, lmbda=False, decomp_algo='tucker', weight_name='log_freq'\n",
    "    data = []\n",
    "    for non_negative in range(2):\n",
    "        for include_empty in range(2):\n",
    "            for cutoff in cutoffs:\n",
    "                for exp in range(10):\n",
    "                    rank = 2**exp\n",
    "                    for weight in weights:\n",
    "                        try:\n",
    "                            evalor = VerbTensorEvaluator(\n",
    "                                non_negative=non_negative, decomp_algo=algo, rank=rank, \n",
    "                                include_empty=include_empty, cutoff=cutoff, weight=weight, \n",
    "                                mode_to_test=mode_to_test)\n",
    "                            score = evalor.test_sim(task_df0)\n",
    "                            data.append((weight, non_negative, algo, rank, include_empty, cutoff, score))\n",
    "                        except FileNotFoundError:\n",
    "                            pass\n",
    "                        except ValueError as e:\n",
    "                            logging.warning((cutoff, rank, e))\n",
    "    df = pd.DataFrame(data, columns=['weight', 'non_negative', 'algo', 'rank', 'include_empty', 'cutoff', \n",
    "                                     'corr'])\n",
    "    return df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_for_files(task_df0, mode_to_test):\n",
    "    data = []\n",
    "    non_negative, decomp_algo = False, 'tucker'\n",
    "    for filen in glob.glob(f'/mnt/permanent/home/makrai/project/verb-tensor/nonempty/tensor/{decomp_algo}*'):\n",
    "        pedigree = os.path.splitext(os.path.basename(filen))[0].split('_', 1)[1].rsplit('_', 3)\n",
    "        if len(pedigree) == 3:\n",
    "            include_empty = True\n",
    "            weight, cutoff, rank = pedigree\n",
    "        elif len(pedigree) == 4:\n",
    "            if pedigree[1] == 'non-empty':\n",
    "                include_empty = False\n",
    "                weight, cutoff, rank = pedigree[0], pedigree[2], pedigree[3]\n",
    "            else:\n",
    "                include_empty = True\n",
    "                weight, cutoff, rank = f'{pedigree[0]}_{pedigree[1]}', pedigree[2], pedigree[3]\n",
    "        else:\n",
    "            include_empty = False\n",
    "            weight, cutoff, rank = f'{pedigree[0]}_{pedigree[1]}', pedigree[3], pedigree[4]\n",
    "        evalor = VerbTensorEvaluator(\n",
    "            mode_to_test=mode_to_test, non_negative=non_negative, decomp_algo=decomp_algo,\n",
    "            weight=weight, include_empty=include_empty, cutoff=cutoff, rank=int(rank))\n",
    "        score = evalor.test_sim(task_df0.reset_index())\n",
    "        data.append((non_negative, decomp_algo, weight, include_empty, cutoff, rank, score))\n",
    "    df = pd.DataFrame(data, columns=['non_negative', 'decomp_algo', 'weight', 'include_empty', 'cutoff', 'rank', 'corr'])\n",
    "    return df.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_negative</th>\n",
       "      <th>decomp_algo</th>\n",
       "      <th>weight</th>\n",
       "      <th>include_empty</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>rank</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>tucker</td>\n",
       "      <td>npmi</td>\n",
       "      <td>True</td>\n",
       "      <td>30000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.074334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>tucker</td>\n",
       "      <td>pmi</td>\n",
       "      <td>False</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.047654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>tucker</td>\n",
       "      <td>npmi</td>\n",
       "      <td>True</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.035873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>tucker</td>\n",
       "      <td>npmi</td>\n",
       "      <td>True</td>\n",
       "      <td>300000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.026332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>tucker</td>\n",
       "      <td>log_freq</td>\n",
       "      <td>True</td>\n",
       "      <td>100000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.024840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    non_negative decomp_algo    weight  include_empty  cutoff rank      corr\n",
       "7          False      tucker      npmi           True   30000   64  0.074334\n",
       "11         False      tucker       pmi          False  100000  128  0.047654\n",
       "9          False      tucker      npmi           True  100000   64  0.035873\n",
       "8          False      tucker      npmi           True  300000   64  0.026332\n",
       "12         False      tucker  log_freq           True  100000   16  0.024840"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = eval_for_files(simlex, mode_to_test='nsubj')#, cutoff=500, rank=32)['tensor_sim']\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cutoff(df):\n",
    "    index_like = ['rank', 'weight', 'non_negative', 'algo']\n",
    "    df1 = df.sort_values(index_like+['corr'], ascending=False).drop_duplicates(index_like)\n",
    "    return df1.sort_values('corr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = eval_for_files(simverb, mode_to_test='ROOT')#, cutoff=500, rank=32)['tensor_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cutoff(df_v).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v[df_v.non_negative==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = eval_for_for(simlex, mode_to_test='dobj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cutoff(df_o).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o[df_o.non_negative==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cutoff(df, col):\n",
    "    for weight in df.weight.unique():\n",
    "        df0 = df[(df.weight==weight)&(df.rank_==256)]\n",
    "        plt.plot(df0.cutoff, df0[col])\n",
    "        plt.legend(df.weight.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank(df, col):\n",
    "    for weight in df.weight.unique():\n",
    "        df0 = df[(df.weight==weight)&(df.cutoff==100)]\n",
    "        plt.plot(df0.rank_, df0[col])\n",
    "        plt.legend(df.weight.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df = compare_100_256(simverb, 'ROOT', 'sim')\n",
    "    plot_cutoff(df, 'sim')\n",
    "    plot_rank(df, 'sim')\n",
    "    df = compare_100_256(simlex, mode_to_test='nsubj', col='SimLex999')\n",
    "    plot_cutoff(df, 'SimLex999')\n",
    "    plot_rank(df, 'SimLex999')\n",
    "    df = compare_100_256(simlex, mode_to_test='dobj', col='SimLex999')\n",
    "    plot_cutoff(df, 'SimLex999')\n",
    "    plot_rank(df, 'SimLex999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df0, col='sim', save_filen=''):#else ''\n",
    "    \n",
    "    df0 = df0[df0.rank_ ==256]\n",
    "    weights = pd.unique(df0.sort_values(col, ascending=False).weight)\n",
    "    for weight in weights:\n",
    "        df = df0[df0.weight==weight].sort_values('rank_')\n",
    "        plt.plot(df.rank_, df[col])#, c=color)\n",
    "    #plt.xscale('log')\n",
    "    _ = plt.legend(weights)\n",
    "    if save_filen:\n",
    "        #plt.rc('text', usetex = True)\n",
    "        #plt.figure(1, figsize = (3, 2))#6, 4))\n",
    "        #plt.savefig('/home/makrai/repo/paper/LREC20/verbtensor/img/{}'.format(save_filen))\n",
    "        filen = '/home/makrai/repo/paper/Coling2020/verbtensor/img/{}.png'.format(save_filen)\n",
    "        plt.savefig(filen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_results(simverb_res)#, save_filen='SimVerb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_results(simlex_subj, col='SimLex999')#, save_filen='simLex-subj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_results(simlex_obj, col='SimLex999')#, save_filen='simLex-obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 SVO triples (_al et_ Sadrzadeh 2011--2014)\n",
    "\n",
    "## 2.1 Datasets\n",
    "\n",
    "  * [GS’11](http://www.cs.ox.ac.uk/activities/compdistmeaning/GS2011data.txt) provided by Grefenstette and Sadrzadeh (EMNLP 2011)\n",
    "      * each verb pair takes the same subject and object\n",
    "      * the task has an aspect of a verb sense disambiguation \n",
    "          * As discussed in previous work\n",
    "            (Kartsaklis and Sadrzadeh, 2013; Milajevs+ 2014; Polajnar+ 2014), GS’11\n",
    "      * For example, the transitive verb “run” is known as polysemous: operate/move\n",
    "        * “run” and “operate” are similar when subj = “people” and obj = “company”\n",
    "        * In the same [context, not similar to] “move”\n",
    "  * ML’10 provided by Mitchell and Lapata (2010),\n",
    "    * pairs of verb-object phrases and\n",
    "  * KS’13 provided by Kartsaklis and Sadrzadeh (2013)\n",
    "    * complements ML’10 by incorporating an appropriate subject for each VO\n",
    "  * KS’14 provided by [Kartsaklis and Sadrzadeh (2014)](https://arxiv.org/abs/1405.2874)\n",
    "    * reannotated version of KS’13 using a cloud sourcing service\n",
    "  * the latter three require one to capture the topical similarity\n",
    "    rather than the disambiguation aspect (Polajnar+ 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_sim_data_dir = '/mnt/permanent/Language/English/Data/verb-similarity/Sadrzadeh/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sim_data(filen):\n",
    "    return pd.read_csv(os.path.join(verb_sim_data_dir, filen), sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Pairs of SVO triples with the same but ambiguous verb (GS11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>landmark</th>\n",
       "      <th>hilo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">accept</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">government</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">proposal</th>\n",
       "      <th>bear</th>\n",
       "      <th>LOW</th>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receive</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>2.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">recommendation</th>\n",
       "      <th>bear</th>\n",
       "      <th>LOW</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receive</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer</th>\n",
       "      <th>conviction</th>\n",
       "      <th>bear</th>\n",
       "      <th>LOW</th>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input\n",
       "verb   subject    object         landmark hilo          \n",
       "accept government proposal       bear     LOW   2.666667\n",
       "                                 receive  HIGH  2.583333\n",
       "                  recommendation bear     LOW   3.500000\n",
       "                                 receive  HIGH  3.333333\n",
       "       lawyer     conviction     bear     LOW   3.333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs11 = read_sim_data('GS2011data.txt').groupby(['verb', 'subject', 'object', 'landmark', 'hilo']).mean()\n",
    "print(gs11.shape)\n",
    "gs11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb\n",
       "accept     20\n",
       "buy        20\n",
       "draw       20\n",
       "meet       20\n",
       "provide    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs11.groupby('verb').size().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark\n",
       "allege     10\n",
       "attract    10\n",
       "test       10\n",
       "supply     10\n",
       "state      10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs11.groupby('landmark').size().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotator_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>adj_subj</th>\n",
       "      <th>subj</th>\n",
       "      <th>landmark</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj_obj</th>\n",
       "      <th>obj</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>statistical</th>\n",
       "      <th>table</th>\n",
       "      <th>show</th>\n",
       "      <th>express</th>\n",
       "      <th>good</th>\n",
       "      <th>result</th>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>statistical</th>\n",
       "      <th>table</th>\n",
       "      <th>show</th>\n",
       "      <th>depict</th>\n",
       "      <th>good</th>\n",
       "      <th>result</th>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>recent</th>\n",
       "      <th>study</th>\n",
       "      <th>show</th>\n",
       "      <th>express</th>\n",
       "      <th>significant</th>\n",
       "      <th>correlation</th>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>recent</th>\n",
       "      <th>study</th>\n",
       "      <th>show</th>\n",
       "      <th>depict</th>\n",
       "      <th>significant</th>\n",
       "      <th>correlation</th>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>annual</th>\n",
       "      <th>figure</th>\n",
       "      <th>show</th>\n",
       "      <th>express</th>\n",
       "      <th>substantial</th>\n",
       "      <th>increase</th>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         annotator_score\n",
       "sentence_id adj_subj    subj   landmark verb    adj_obj     obj                         \n",
       "1           statistical table  show     express good        result                  6.06\n",
       "2           statistical table  show     depict  good        result                  5.90\n",
       "3           recent      study  show     express significant correlation             5.72\n",
       "4           recent      study  show     depict  significant correlation             5.92\n",
       "5           annual      figure show     express substantial increase                5.74"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentence_id', 'adj_subj', 'subj', 'landmark', 'verb', 'adj_obj', 'obj']\n",
    "gs12 = read_sim_data('GS2012data.txt').groupby(cols).mean().drop(columns=['annotator_id'])\n",
    "gs12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotator_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>adj_subj</th>\n",
       "      <th>subj</th>\n",
       "      <th>landmark</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj_obj</th>\n",
       "      <th>obj</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>private</th>\n",
       "      <th>company</th>\n",
       "      <th>file</th>\n",
       "      <th>register</th>\n",
       "      <th>annual</th>\n",
       "      <th>account</th>\n",
       "      <td>5.441860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>private</th>\n",
       "      <th>company</th>\n",
       "      <th>file</th>\n",
       "      <th>smooth</th>\n",
       "      <th>annual</th>\n",
       "      <th>account</th>\n",
       "      <td>2.302326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>young</th>\n",
       "      <th>woman</th>\n",
       "      <th>file</th>\n",
       "      <th>register</th>\n",
       "      <th>long</th>\n",
       "      <th>nail</th>\n",
       "      <td>2.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>young</th>\n",
       "      <th>woman</th>\n",
       "      <th>file</th>\n",
       "      <th>smooth</th>\n",
       "      <th>long</th>\n",
       "      <th>nail</th>\n",
       "      <td>5.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>local</th>\n",
       "      <th>government</th>\n",
       "      <th>file</th>\n",
       "      <th>register</th>\n",
       "      <th>criminal</th>\n",
       "      <th>charge</th>\n",
       "      <td>5.441860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    annotator_score\n",
       "sentence_id adj_subj subj       landmark verb     adj_obj  obj                     \n",
       "1           private  company    file     register annual   account         5.441860\n",
       "2           private  company    file     smooth   annual   account         2.302326\n",
       "3           young    woman      file     register long     nail            2.069767\n",
       "4           young    woman      file     smooth   long     nail            5.023256\n",
       "5           local    government file     register criminal charge          5.441860"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentence_id', 'adj_subj', 'subj', 'landmark', 'verb', 'adj_obj', 'obj']\n",
    "gsk13 = read_sim_data('pickering-judgements.txt').groupby(cols).mean().drop(columns=['annotator_id'])\n",
    "gsk13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject1</th>\n",
       "      <th>verb1</th>\n",
       "      <th>object1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>verb2</th>\n",
       "      <th>object2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sell</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">property</th>\n",
       "      <th>family</th>\n",
       "      <th>buy</th>\n",
       "      <th>home</th>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th>hold</th>\n",
       "      <th>meeting</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">author</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">write</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">book</th>\n",
       "      <th>delegate</th>\n",
       "      <th>buy</th>\n",
       "      <th>land</th>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <th>hear</th>\n",
       "      <th>word</th>\n",
       "      <td>2.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <th>read</th>\n",
       "      <th>word</th>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   score\n",
       "subject1 verb1 object1  subject2 verb2 object2          \n",
       "agent    sell  property family   buy   home     2.777778\n",
       "                        group    hold  meeting  1.666667\n",
       "author   write book     delegate buy   land     1.500000\n",
       "                        man      hear  word     2.055556\n",
       "                        writer   read  word     2.777778"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2']\n",
    "ks13_mitchell = read_sim_data('emnlp2013_ml.txt').groupby(cols).mean()\n",
    "print(ks13_mitchell.shape)\n",
    "ks13_mitchell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(i):\n",
    "    return ['subject{}'.format(i), 'verb{}'.format(i), 'object{}'.format(i)]\n",
    "\n",
    "def get_one_sent_from_pair(i):\n",
    "    df = ks13_mitchell.reset_index()[get_cols(i)]\n",
    "    df.columns = get_cols('')\n",
    "    return df\n",
    "\n",
    "ks13_long = pd.concat(get_one_sent_from_pair(i) for i in [1, 2])\n",
    "ks13_long = ks13_long.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Kartsaklis and Sadrzadeh, Turk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject1</th>\n",
       "      <th>verb1</th>\n",
       "      <th>object1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>verb2</th>\n",
       "      <th>object2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent</td>\n",
       "      <td>sell</td>\n",
       "      <td>property</td>\n",
       "      <td>family</td>\n",
       "      <td>buy</td>\n",
       "      <td>home</td>\n",
       "      <td>3.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent</td>\n",
       "      <td>sell</td>\n",
       "      <td>property</td>\n",
       "      <td>group</td>\n",
       "      <td>hold</td>\n",
       "      <td>meeting</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author</td>\n",
       "      <td>write</td>\n",
       "      <td>book</td>\n",
       "      <td>delegate</td>\n",
       "      <td>buy</td>\n",
       "      <td>land</td>\n",
       "      <td>1.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author</td>\n",
       "      <td>write</td>\n",
       "      <td>book</td>\n",
       "      <td>man</td>\n",
       "      <td>hear</td>\n",
       "      <td>word</td>\n",
       "      <td>1.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>write</td>\n",
       "      <td>book</td>\n",
       "      <td>writer</td>\n",
       "      <td>read</td>\n",
       "      <td>word</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject1  verb1   object1  subject2 verb2  object2     score\n",
       "0    agent   sell  property    family   buy     home  3.125000\n",
       "1    agent   sell  property     group  hold  meeting  1.166667\n",
       "2   author  write      book  delegate   buy     land  1.130435\n",
       "3   author  write      book       man  hear     word  1.640000\n",
       "4   author  write      book    writer  read     word  3.166667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2']\n",
    "ks13_turk = read_sim_data('emnlp2013_turk.txt').groupby(cols).mean().drop(columns=['annotator']).reset_index()\n",
    "ks13_turk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb1\n",
       "achieve    5\n",
       "use        5\n",
       "win        4\n",
       "provide    4\n",
       "fight      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks13_turk.groupby('verb1').size().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb2\n",
       "use        7\n",
       "provide    5\n",
       "leave      4\n",
       "buy        4\n",
       "reach      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks13_turk.groupby('verb2').size().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 [Verb prediction task by Jenatton+ (NIPS 2012)](https://everest.hds.utc.fr/doku.php?id=en:lfmnips12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/mnt/permanent/Language/English/Data/verb-similarity/SVO-tensor-dataset/'\n",
    "def get_index(pos):\n",
    "    with open(os.path.join(dataset_dir, 'svo-{}s.lst'.format(pos))) as infile:\n",
    "        return {i+1: ' '.join(line.strip().split('_')[2:-1]) for i, line in enumerate(infile)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df = pd.read_csv(os.path.join(dataset_dir, 'svo_data_train_1000000.dat'), sep='\\t', header=None, \n",
    "                     names=['subject', 'verb', 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_verb = get_index('verb')\n",
    "index_noun = get_index('noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df.subject = svo_df.subject.apply(index_noun.get)\n",
    "svo_df.verb = svo_df.verb.apply(index_verb.get)\n",
    "svo_df.object = svo_df.object.apply(index_noun.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239205</th>\n",
       "      <td>foreign minister</td>\n",
       "      <td>say</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58505</th>\n",
       "      <td>executive director</td>\n",
       "      <td>see</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724700</th>\n",
       "      <td>activity</td>\n",
       "      <td>imply</td>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704689</th>\n",
       "      <td>democrat</td>\n",
       "      <td>file</td>\n",
       "      <td>signature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429405</th>\n",
       "      <td>director</td>\n",
       "      <td>have</td>\n",
       "      <td>phone number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subject   verb        object\n",
       "239205    foreign minister    say         thing\n",
       "58505   executive director    see           www\n",
       "724700            activity  imply          risk\n",
       "704689            democrat   file     signature\n",
       "429405            director   have  phone number"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Similarity (KS Turk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('niact', False, '1000000', '512')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/repo/verb-tensor/eval_tensor.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(word, mode_i)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/vtensor/lib/python3.7/site-packages/bidict/_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;34m\"\"\"*x.__getitem__(key)　⟺　x[key]*\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwdm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'charity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-be2dcfd30fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_for_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mks13_turk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-420a01ac9297>\u001b[0m in \u001b[0;36meval_for_files\u001b[0;34m(task_df0, mode_to_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m         evalor = VerbTensorEvaluator(mode_to_test=mode_to_test, non_negative=non_negative, decomp_algo=decomp_algo, \n\u001b[1;32m     10\u001b[0m                                      weight=weight, include_empty=include_empty, cutoff=cutoff, rank=rank)\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_df0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecomp_algo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'non_negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decomp_algo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'include_empty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cutoff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'corr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/verb-tensor/eval_tensor.py\u001b[0m in \u001b[0;36mtest_sim\u001b[0;34m(self, task_df0)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_w_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery1_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery2_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             series = task_df[query_w_col].apply(\n\u001b[0;32m--> 131\u001b[0;31m                 lambda word: self.lookup(word, mode_i=mode_i))\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mtask_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_v'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_w_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode_to_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/vtensor/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4133\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4134\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4135\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/repo/verb-tensor/eval_tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_w_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery1_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery2_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             series = task_df[query_w_col].apply(\n\u001b[0;32m--> 131\u001b[0;31m                 lambda word: self.lookup(word, mode_i=mode_i))\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mtask_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_v'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_w_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode_to_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/verb-tensor/eval_tensor.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(word, mode_i)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moov\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "df = eval_for_files(ks13_turk, mode_to_test='svo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('corr', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 5\n",
    "pylab.rcParams['figure.figsize'] = (2*height, height)\n",
    "matplotlib.rcParams.update({'font.size': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['log_freq', 'npmi', 'pmi_sali', 'pmi', 'niact', 'iact_sali', 'iact', 'ldice_sali', 'ldice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.non_negative==0)&(df.algo=='tucker')&(df['rank']==64)&(df.cutoff>=50000)&(df.cutoff<=100000)]\n",
    "df1.pivot_table('corr', ['cutoff'], 'weight')[columns].plot(kind='bar', rot=0)\n",
    "plt.savefig('/home/makrai/repo/paper/CONLL21/verbtensor/img/svo-64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.non_negative==0)&(df.algo=='tucker')&(df['weight']=='npmi')]\n",
    "plt.scatter(df1.cutoff, df1['rank'], c=df1['corr'])\n",
    "#plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.colorbar()\n",
    "plt.savefig('/home/makrai/repo/paper/CONLL21/verbtensor/img/svo-npmi-scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df.weight=='npmi')&(df.non_negative==False)]\n",
    "df2.pivot_table('corr', 'rank', 'cutoff').plot(kind='bar', rot=0)\n",
    "plt.savefig('/home/makrai/repo/paper/CONLL21/verbtensor/img/svo-npmi-bar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.non_negative==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor = VerbTensorEvaluator()#weight='npmi', non_negative=True, include_empty=False, cutoff=500000, mode_to_test='svo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalor.test_sim(ks13_turk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = eval_for_for(ks13_turk, mode_to_test='svo', algo='parafac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[df_p['rank']==64].pivot_table('corr', 'weight', 'cutoff').plot(kind='bar', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Verb prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rank = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time VerbTensorEvaluator(rank=gs_rank).predict_verb(gs11.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in weights:\n",
    "    try:\n",
    "        VerbTensorEvaluator(rank=gs_rank, weight=weight).predict_verb(gs11.reset_index())\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VerbTensorEvaluator(rank=128).predict_verb(gs11.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in [50000,200000]:\n",
    "    try:\n",
    "        VerbTensorEvaluator(rank=gs_rank, cutoff=cutoff).predict_verb(gs11.reset_index())\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VerbTensorEvaluator().predict_verb(svo_df) # Jenatton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks13_turk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VerbTensorEvaluator().predict_verb(ks13_turk, cols_suff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VerbTensorEvaluator().predict_verb(ks13_turk, cols_suff=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attic: Exploring GS11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim = gs11.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.hilo = (svo_sim=='HIGH').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ordered = [\"subject\", \"verb\", \"landmark\", \"object\", \"input\", \"hilo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim[cols_ordered].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.groupby('landmark').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.groupby('verb').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_for_weight(task_df0, mode_to_test='svo', cutoff=2000, rank=128):\n",
    "    # normlz_vocb=True, lmbda=False, decomp_algo='tucker', weight_name='log_freq'\n",
    "    data = []\n",
    "    for weight_name in weights:\n",
    "        try:\n",
    "            score_d = evalor.test_sim(task_df0, mode_to_test=mode_to_test, \n",
    "                                      cutoff=cutoff, rank=rank, weight=weight_name)\n",
    "            data.append((cutoff, rank, weight_name, score_d))\n",
    "        except FileNotFoundError as e:\n",
    "            logging.warning(weight_name)\n",
    "        except ValueError as e:\n",
    "            logging.warning((cutoff, rank, e))\n",
    "    df = pd.DataFrame(data, columns=['cutoff', 'rank', 'weight', 'corr'])\n",
    "    return df.sort_values('corr', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtens",
   "language": "python",
   "name": "vtens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

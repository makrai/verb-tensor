{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "        format='%(levelname)-8s [%(lineno)d] %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "from tikzplotlib import save as tikz_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_tensor import test_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 One-mode similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data\n",
    "\n",
    "### 1.1.1 [SimVerb](http://people.ds.cam.ac.uk/dsg40/simverb.html) (Gerz+ EMNLP 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb = pd.read_csv('/mnt/permanent/Language/English/Data/verb-similarity/simverb-3500/SimVerb-3500.txt', sep='\\t',\n",
    "                      header=None, names=['verb1', 'verb2', 'pos', 'sim', 'rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb.groupby('rel').sim.describe(percentiles=[]).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 SimLex-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex = pd.read_csv('/mnt/permanent/Language/English/Data/SimLex-999/SimLex-999.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* conc(w1): The concreteness rating of word1 on a scale of 1-7. Taken from the University of South Florida Free Association Norms database. \n",
    "\n",
    "* conc(w2): The concreteness rating of word2 on a scale of 1-7. Taken from the University of South Florida Free Association Norms database. \n",
    "\n",
    "* concQ: The quartile the pair occupies based on the two concreteness ratings. Used for some analyses in the above paper. \n",
    "\n",
    "* Assoc(USF): The strength of free association from word1 to word2. Values are taken from the University of South Florida Free Association Dataset. \n",
    "\n",
    "* SimAssoc333: Binary indicator of whether the pair is one of the 333 most associated in the dataset (according to Assoc(USF)). This subset of SimLex999 is often the hardest for computational models to capture because the noise from high association can confound the similarity rating. See the paper for more details. \n",
    "\n",
    "* SD(SimLex): The standard deviation of annotator scores when rating this pair. Low values indicate good agreement between the 15+ annotators on the similarity value SimLex999. Higher scores indicate less certainty. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex.groupby('POS').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Testing the verb tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_columns_from_filen(sim_df, col='sim'):#\n",
    "    sim_df = sim_df.drop(col)\n",
    "    sim_df = sim_df.to_frame().reset_index()\n",
    "    sim_df [['_t', '_s', 'weight', 'rank_']] = pd.DataFrame(sim_df['index'].str.rsplit('_').values.tolist())\n",
    "    sim_df = sim_df[sim_df.weight.isna()==0]\n",
    "    sim_df.rank_ = sim_df.rank_.astype(int)\n",
    "    #sim_df['weight'] = pd.DataFrame(sim_df['weight'].str.split('_', 2).values.tolist())[2]\n",
    "    sim_df = sim_df.drop(columns='index')\n",
    "    #sim_df = sim_df.drop(labels=[0])\n",
    "    sim_df =sim_df[sim_df.isna().sum(axis=1)==0]\n",
    "    return sim_df.sort_values(col, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb_res = test_sim(simverb, mode_to_test='ROOT')\n",
    "simverb_res = df_columns_from_filen(simverb_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_subj = test_sim(simlex, mode_to_test='nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_subj = df_columns_from_filen(simlex_subj, col='SimLex999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_obj = test_sim(simlex, mode_to_test='dobj')\n",
    "simlex_obj = df_columns_from_filen(simlex_obj, col='SimLex999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb_res.sort_values('sim', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_subj.sort_values('SimLex999', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_obj.sort_values('SimLex999', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = pd.unique(simverb_res.weight)\n",
    "\n",
    "def plot_results(df0, col='sim', save_filen=''):#else ''\n",
    "    #df0 = df0[df0.rank_ ==128]            \n",
    "    weights = pd.unique(df0.sort_values(col, ascending=False).weight)\n",
    "    for weight in weights:\n",
    "        df = df0[df0.weight==weight].sort_values('rank_')\n",
    "        plt.plot(df.rank_, df[col])#, c=color)\n",
    "    #plt.xscale('log')\n",
    "    _ = plt.legend(weights)\n",
    "    if save_filen:\n",
    "        tikz_save('/home/makrai/repo/paper/LREC20/verbtensor/img/{}.tikz'.format(save_filen), \n",
    "                  figurewidth = '\\\\columnwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(simverb_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(simlex_subj, col='SimLex999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_subj[simlex_subj.rank_==128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(simlex_obj, col='SimLex999')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 SVO triples (_al et_ Sadrzadeh 2011--2014)\n",
    "\n",
    "## 2.1 Datasets\n",
    "\n",
    "  * [GS’11](http://www.cs.ox.ac.uk/activities/compdistmeaning/GS2011data.txt) provided by Grefenstette and Sadrzadeh (EMNLP 2011)\n",
    "      * each verb pair takes the same subject and object\n",
    "      * the task has an aspect of a verb sense disambiguation \n",
    "          * As discussed in previous work\n",
    "            (Kartsaklis and Sadrzadeh, 2013; Milajevs+ 2014; Polajnar+ 2014), GS’11\n",
    "      * For example, the transitive verb “run” is known as polysemous: operate/move\n",
    "        * “run” and “operate” are similar when subj = “people” and obj = “company”\n",
    "        * In the same [context, not similar to] “move”\n",
    "  * ML’10 provided by Mitchell and Lapata (2010),\n",
    "    * pairs of verb-object phrases and\n",
    "  * KS’13 provided by Kartsaklis and Sadrzadeh (2013)\n",
    "    * complements ML’10 by incorporating an appropriate subject for each VO\n",
    "  * KS’14 provided by [Kartsaklis and Sadrzadeh (2014)](https://arxiv.org/abs/1405.2874)\n",
    "    * reannotated version of KS’13 using a cloud sourcing service\n",
    "  * the latter three require one to capture the topical similarity\n",
    "    rather than the disambiguation aspect (Polajnar+ 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_sim_data_dir = '/mnt/permanent/Language/English/Data/verb-similarity/Sadrzadeh/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sim_data(filen):\n",
    "    return pd.read_csv(os.path.join(verb_sim_data_dir, filen), sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Pairs of SVO triples with the same but ambiguous verb (GS11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs11 = read_sim_data('GS2011data.txt').groupby(['verb', 'subject', 'object', 'landmark', 'hilo']).mean()\n",
    "print(gs11.shape)\n",
    "gs11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentence_id', 'adj_subj', 'subj', 'landmark', 'verb', 'adj_obj', 'obj']\n",
    "gs12 = read_sim_data('GS2012data.txt').groupby(cols).mean().drop(columns=['annotator_id'])\n",
    "gs12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentence_id', 'adj_subj', 'subj', 'landmark', 'verb', 'adj_obj', 'obj']\n",
    "gsk13 = read_sim_data('pickering-judgements.txt').groupby(cols).mean().drop(columns=['annotator_id'])\n",
    "gsk13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2']\n",
    "ks13_mitchell = read_sim_data('emnlp2013_ml.txt').groupby(cols).mean()\n",
    "print(ks13_mitchell.shape)\n",
    "ks13_mitchell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cols = lambda i: ['subject{}'.format(i), 'verb{}'.format(i), 'object{}'.format(i)]\n",
    "def get_one_sent_from_pair(i):\n",
    "    df = ks13_mitchell.reset_index()[get_cols(i)]\n",
    "    df.columns = get_cols('')\n",
    "    return df\n",
    "ks13_long = pd.concat(get_one_sent_from_pair(i) for i in [1, 2])\n",
    "ks13_long = ks13_long.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Kartsaklis and Sadrzadeh, Turk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2']\n",
    "ks13_turk = read_sim_data('emnlp2013_turk.txt').groupby(cols).mean().drop(columns=['annotator'])\n",
    "ks13_turk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 [Verb prediction task by Jenatton+ (NIPS 2012)](https://everest.hds.utc.fr/doku.php?id=en:lfmnips12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/mnt/permanent/Language/English/Data/verb-similarity/SVO-tensor-dataset/'\n",
    "def get_index(pos):\n",
    "    with open(os.path.join(dataset_dir, 'svo-{}s.lst'.format(pos))) as infile:\n",
    "        return {i+1: ' '.join(line.strip().split('_')[2:-1]) for i, line in enumerate(infile)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df = pd.read_csv(os.path.join(dataset_dir, 'svo_data_train_1000000.dat'), sep='\\t', header=None, \n",
    "                     names=['subject', 'verb', 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_verb = get_index('verb')\n",
    "index_noun = get_index('noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df.subject = svo_df.subject.apply(index_noun.get)\n",
    "svo_df.verb = svo_df.verb.apply(index_verb.get)\n",
    "svo_df.object = svo_df.object.apply(index_noun.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Similarity (KS Turk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_sim(ks13_turk, mode_to_test='svo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Verb prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_tensor import predict_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_weight_and_rank(max_exp_plus_one=7):\n",
    "    for weight in ['log_freq', 'pmi', 'iact_info', 'salience', 'iact_sali', 'log_dice', 'dice_sali']:\n",
    "        logging.info(weight)\n",
    "        for exp in range(3, max_exp_plus_one):\n",
    "            rank = 2 ** exp\n",
    "            logging.info('\\t{}'.format(rank))\n",
    "            try:\n",
    "                predict_verb(svo_df, weight, rank)\n",
    "            except FileNotFoundError as e:\n",
    "                logging.warning(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for_weight_and_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 44 k $\\times$ 9 k $\\times$ 39 k-s tenosor:\n",
    "\n",
    "|assoc measure|rank|verb|\n",
    "|-|-|-|\n",
    "|pmi|256|318|\n",
    "|salience|128|318|\n",
    "|log-Dice|128|270|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.sum(numeric_only=True).sort_values(ascending=False).head()/svo_sim.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|verb|`* 1`|`* lmbda`|\n",
    "|----|--|------|\n",
    "|unnorm|130|**272**|\n",
    "|norm|0|24|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majoroty baseline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'verb'\n",
    "svo_sim.groupby(target).size().sort_values()/svo_sim.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attic: Exploring GS11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim = gs11.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.hilo = (svo_sim=='HIGH').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ordered = [\"subject\", \"verb\", \"landmark\", \"object\", \"input\", \"hilo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim[cols_ordered].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.groupby('landmark').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.groupby('verb').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_sim.corr(method='spearman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
